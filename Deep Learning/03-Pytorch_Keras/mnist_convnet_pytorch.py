# -*- coding: utf-8 -*-
"""MNIST_ConvNet_PyTorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KRrP3MtozDfd70h48X4zl7TD9kB71MbP

# Video-Aula
"""

from IPython.display import YouTubeVideo
YouTubeVideo('xRC95W55Y8g')

"""## Obtenção dos Dados

Este código baixa os arquivos do [_dataset_ MNIST](https://en.wikipedia.org/wiki/MNIST_database) a partir do [site](http://yann.lecun.com/exdb/mnist/) do [Prof. Yann LeCun](https://en.wikipedia.org/wiki/Yann_LeCun).
"""

# Imagens de treinamento
!wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz -O train-images-idx3-ubyte.gz
# Rótulos (classes)
!wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz -O train-labels-idx1-ubyte.gz
# Imagens de validação
!wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz -O t10k-images-idx3-ubyte.gz
# Rótulos de validação (classes)
!wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz -O t10k-labels-idx1-ubyte.gz

"""Abaixo extraímos os arquivos comprimidos. """

# Extrai os arquivos treinamento
!gunzip -f *.gz

"""## Importação de Bibliotecas

"""

# Importa as bibliotecas que usaremos

import torch
import torch.nn as nn
import torch.functional as F
import torch.optim as optim

import numpy as np
from matplotlib import pyplot as plt

# Ajusta os parâmetro de precisão para
# as variáveis que serão impressas na tela

torch.set_printoptions(precision=2, sci_mode=False)
np.set_printoptions(precision=2)

"""## Leitura dos Dados

Abaixo definimos as funções auxiliares para leitura do arquivo de imagens
"""

from struct import unpack

def read_imgs(img_filename):
  ''' Esta função lê o arquivo de imagens
      da base de dados MNIST
  '''

  # Abre o arquivo
  img_file = open(img_filename,'rb')

  # Lê o cabeçalho do arquivo
  magic = unpack('>i', img_file.read(4))[0]
  total = unpack('>i', img_file.read(4))[0]
  height = unpack('>i', img_file.read(4))[0]
  width = unpack('>i', img_file.read(4))[0]

  # Verifica se o arquivo passa no teste
  # básico (este número deve ser sempre 2051)
  if magic != 2051:
    print('Erro, este arquivo não parece ser um arquivo de imagens MNIST')

  # Aqui criamos a array do NumPy que armazenará
  # as imagens
  imgs = np.zeros((total,height,width), dtype=float)

  # Nesse laço vamos lendo cada pixel e preenchendo
  # no array
  for k in range(total): # Cada amostra k
    for i in range(height): # Cada linha i
      for j in range(width): # Cada coluna j
        imgs[k,i,j] = ord(img_file.read(1)) # Lemos 1 byte
  
  # Retornamos o array preenchido
  # e já normalizado para valores
  # entre zero e um
  return imgs / 255.0

"""De forma semelhante ao realizado acima, aqui abaixo definimos as funções auxiliares para leitura do arquivo de rótulos."""

def read_labels(labels_filename):
  ''' Esta função lê o arquivo de rótulos
      da base de dados MNIST
  '''

  # Abre o arquivo
  labels_file = open(labels_filename,'rb')

  # Lê o cabeçalho do arquivo
  magic = unpack('>i', labels_file.read(4))[0]
  total = unpack('>i', labels_file.read(4))[0]

  # Verifica se o arquivo passa no teste
  # básico (este número deve ser sempre 2051)
  if magic != 2049:
    print('Erro, este arquivo não parece ser um arquivo de imagens MNIST')

  # Aqui criamos a array do NumPy que armazenará
  # as imagens
  labels = np.zeros((total), dtype=int)

  # Nesse laço vamos lendo cada label e preenchendo
  # no array
  for k in range(total): # Cada amostra k
    labels[k] = ord(labels_file.read(1)) # Lemos 1 byte
  
  # Retornamos o array preenchido
  return labels

"""Nas linhas abaixo chamamos as função de leitura para carregar as imagens e os respectivos rótulos"""

# Dados de treinamento

Xt = read_imgs('train-images-idx3-ubyte')
Yt = read_labels('train-labels-idx1-ubyte')

# Dados de validação
Xv = read_imgs('t10k-images-idx3-ubyte')
Yv = read_labels('t10k-labels-idx1-ubyte')

"""## Embaralhamento das Amostras"""

def shuffle_pair(x, y):
  idxs = list(range(len(y)))
  np.random.shuffle(idxs)
  return x[idxs], y[idxs]

Xt, Yt = shuffle_pair(Xt, Yt)
Xv, Yv = shuffle_pair(Xv, Yv)

"""## Conversão para PyTorch"""

Xt = torch.tensor(Xt)
Yt = torch.tensor(Yt, dtype=torch.long)
Xv = torch.tensor(Xv)
Yv = torch.tensor(Yv, dtype=torch.long)

Xt = Xt.unsqueeze(1)
Xv = Xv.unsqueeze(1)

"""# Rede Neural

O código abaixo definimos uma rede neural convolucional.
"""

class ConvNet(nn.Module):
  def __init__(self):
    super(ConvNet, self).__init__()
    self.conv1 = nn.Conv2d(1, 5, kernel_size=5)  #  1x28x28 => 5x24x24
    self.pool1 = nn.MaxPool2d(2, 2)
    self.conv2 = nn.Conv2d(5, 8, kernel_size=3)  #  5x12x12 => 10x10x10
    self.drp1 = nn.Dropout2d(0.25)               #   8x5x5 => 
    self.pool2 = nn.MaxPool2d(2, 2)
    self.lin1 = nn.Linear(200, 10)               #     200 => 10
    
  def forward(self, x):
    x = self.conv1(x)
    x = torch.relu(x)
    x = self.pool1(x)
    x = self.conv2(x)
    x = self.drp1(x)
    x = torch.relu(x)
    x = self.pool2(x)
    x = x.view(-1, 200)
    x = self.lin1(x)
    return x

cnn = ConvNet()
print(cnn)

"""# Treinamento

Esta rede neural será treinada em $1001$ épocas, e isso levará em torno de $20$ minutos (aproximadamente $2$ minutos por época)
"""

# Aqui criamos o otimizador e a função
# de perda

opt = optim.Adam(cnn.parameters(), lr=0.0001)
loss = nn.CrossEntropyLoss()

# Movemos tudo para a GPU
# (essa parte é opcional)

gpu = torch.device("cuda:0")
cnn = cnn.to(gpu)
Xt = Xt.to(gpu, dtype=torch.float)
Yt = Yt.to(gpu, dtype=torch.long)
Xv = Xv.to(gpu, dtype=torch.float)
Yv = Yv.to(gpu, dtype=torch.long)

# Essa função serve para verificarmos
# a acurácia dos resultados, seja
# nos pares de treinamento, seja
# nos pares de validação.

def evaluate(x, y_hat):
  y = cnn(x).argmax(dim=1)
  return 100*float((y == y_hat).sum()) / len(y)

# Treinamento da rede neural
# Treinamento por 10 épocas
# usando lotes de 16 amostras
# (pode repetir essa célula várias
#  vezes para tentar aumentar a
#  acurácia)

for j in range(10):
  for i in range(0,len(Yt),16):
    x = Xt[i:i+16,:,:,:]
    y_hat = Yt[i:i+16]
    opt.zero_grad()
    y = cnn(x)
    e = loss(y, y_hat)
    e.backward()
    opt.step()
  print(float(e), evaluate(Xt, Yt))

"""# Avaliação dos Resultados"""

# Essa linha de código coloca a
# rede neural no modo de avaliação
# (tira do modo de treinamento).
# Dessa forma o dropout é desativado

cnn.eval()

"""Abaixo mostramos, finalmente, a acurácia nos dados de validação. O valor pode até superar a acurácia do treinamento, já que aqui dropout está desabilitado."""

print('Acurácia nos dados de validação:', evaluate(Xv, Yv))

"""No código abaixo mostramos alguns exemplos de saída calculada pela rede neural e respectiva saída desejada e imagem correspondente."""

for _ in range(5):
  idx = np.random.randint(0, len(Yv))
  x = Xv[idx,0,:,:].cpu()
  y = int(cnn(Xv[idx,:,:,:].unsqueeze(1)).argmax(dim=1))
  print('y =', y, 'y_hat =', int(Yv[idx]))
  plt.imshow(x, cmap='gray')
  plt.show()

"""A linha de código abaixo coloca a rede neural novamente em modo treinamento."""

cnn.train()